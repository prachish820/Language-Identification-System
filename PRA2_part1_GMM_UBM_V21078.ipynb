{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMvbnzJd1LyMcP2gCytuDEV",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/prachish820/Language-Identification-System/blob/main/PRA2_part1_GMM_UBM_V21078.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### *Drive link to access data*\n",
        "\n",
        "[Extracted data](https://drive.google.com/drive/folders/11_s9A7INRwtAeUo3bdTIPXbOgMrAzs9g?usp=sharing)\n"
      ],
      "metadata": {
        "id": "j6AdcRzvq6BN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oA04_-MGpxUa"
      },
      "outputs": [],
      "source": [
        "# Importing libraries\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "from csv import reader\n",
        "from sklearn import datasets\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn import mixture\n",
        "from sklearn.mixture import BayesianGaussianMixture"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# GMM-UBM system to model each class conditional density\n",
        "\n",
        "# CLASSES  0 - asm\n",
        "#          1 - ben\n",
        "#          2 - eng\n",
        "#          3 - guj\n",
        "#          4 - Hin\n",
        "#          5 - kan\n",
        "#          6 - mal\n",
        "#          7 - mar\n",
        "#          8 - odi\n",
        "#          9 - pun\n",
        "#          10- tam\n",
        "#          11- tel"
      ],
      "metadata": {
        "id": "GQfjrW00qJ82"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training data for all language appended in one file for each. Change the directory location accordingly.\n",
        "asm_pb_train = pd.read_csv(r'C:\\Users\\PRACHI\\OneDrive\\Desktop\\PRA_2_LID\\PRA_A2_Extracted_GMM\\asm\\PB_train.csv')\n",
        "ben_pb_train = pd.read_csv(r'C:\\Users\\PRACHI\\OneDrive\\Desktop\\PRA_2_LID\\PRA_A2_Extracted_GMM\\ben\\PB_train.csv')\n",
        "eng_pb_train = pd.read_csv(r'C:\\Users\\PRACHI\\OneDrive\\Desktop\\PRA_2_LID\\PRA_A2_Extracted_GMM\\eng\\PB_train.csv')\n",
        "guj_pb_train = pd.read_csv(r'C:\\Users\\PRACHI\\OneDrive\\Desktop\\PRA_2_LID\\PRA_A2_Extracted_GMM\\guj\\PB_train.csv')\n",
        "hin_pb_train = pd.read_csv(r'C:\\Users\\PRACHI\\OneDrive\\Desktop\\PRA_2_LID\\PRA_A2_Extracted_GMM\\hin\\PB_train.csv')\n",
        "kan_pb_train = pd.read_csv(r'C:\\Users\\PRACHI\\OneDrive\\Desktop\\PRA_2_LID\\PRA_A2_Extracted_GMM\\kan\\PB_train.csv')\n",
        "mal_pb_train = pd.read_csv(r'C:\\Users\\PRACHI\\OneDrive\\Desktop\\PRA_2_LID\\PRA_A2_Extracted_GMM\\mal\\PB_train.csv')\n",
        "mar_pb_train = pd.read_csv(r'C:\\Users\\PRACHI\\OneDrive\\Desktop\\PRA_2_LID\\PRA_A2_Extracted_GMM\\mar\\PB_train.csv')\n",
        "odi_pb_train = pd.read_csv(r'C:\\Users\\PRACHI\\OneDrive\\Desktop\\PRA_2_LID\\PRA_A2_Extracted_GMM\\odi\\PB_train.csv')\n",
        "pun_pb_train = pd.read_csv(r'C:\\Users\\PRACHI\\OneDrive\\Desktop\\PRA_2_LID\\PRA_A2_Extracted_GMM\\pun\\PB_train.csv')\n",
        "tam_pb_train = pd.read_csv(r'C:\\Users\\PRACHI\\OneDrive\\Desktop\\PRA_2_LID\\PRA_A2_Extracted_GMM\\tam\\PB_train.csv')\n",
        "tel_pb_train = pd.read_csv(r'C:\\Users\\PRACHI\\OneDrive\\Desktop\\PRA_2_LID\\PRA_A2_Extracted_GMM\\tel\\PB_train.csv')\n",
        "print(\"Read training files\")"
      ],
      "metadata": {
        "id": "e2m_7rfHqqxN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Pooling all language training data together\n",
        "\n",
        "X_1 = pd.concat([asm_pb_train, ben_pb_train])\n",
        "X_2 = pd.concat([X_1, eng_pb_train])\n",
        "X_3 = pd.concat([X_2, guj_pb_train])\n",
        "X_4 = pd.concat([X_3, hin_pb_train])\n",
        "X_5 = pd.concat([X_4, kan_pb_train])\n",
        "X_6 = pd.concat([X_5, mal_pb_train])\n",
        "X_7 = pd.concat([X_6, mar_pb_train])\n",
        "X_8 = pd.concat([X_7, odi_pb_train])\n",
        "X_9 = pd.concat([X_8, pun_pb_train])\n",
        "X_10 = pd.concat([X_9, tam_pb_train])\n",
        "X_df = pd.concat([X_10, tel_pb_train])\n",
        "X_train = X_df.to_numpy()\n",
        "print(X_train.shape)"
      ],
      "metadata": {
        "id": "6BXM9EzDteSI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# List of all the folder consisting the test csv for each audio file for PB data\n",
        "\n",
        "PB_Test_list = [r'C:\\Users\\PRACHI\\OneDrive\\Desktop\\PRA_2_LID\\PRA_A2_Extracted_GMM_test\\asm\\PB',\n",
        "                r'C:\\Users\\PRACHI\\OneDrive\\Desktop\\PRA_2_LID\\PRA_A2_Extracted_GMM_test\\ben\\PB',\n",
        "                r'C:\\Users\\PRACHI\\OneDrive\\Desktop\\PRA_2_LID\\PRA_A2_Extracted_GMM_test\\eng\\PB',\n",
        "                r'C:\\Users\\PRACHI\\OneDrive\\Desktop\\PRA_2_LID\\PRA_A2_Extracted_GMM_test\\guj\\PB',\n",
        "                r'C:\\Users\\PRACHI\\OneDrive\\Desktop\\PRA_2_LID\\PRA_A2_Extracted_GMM_test\\hin\\PB',\n",
        "                r'C:\\Users\\PRACHI\\OneDrive\\Desktop\\PRA_2_LID\\PRA_A2_Extracted_GMM_test\\kan\\PB',\n",
        "                r'C:\\Users\\PRACHI\\OneDrive\\Desktop\\PRA_2_LID\\PRA_A2_Extracted_GMM_test\\mal\\PB',\n",
        "                r'C:\\Users\\PRACHI\\OneDrive\\Desktop\\PRA_2_LID\\PRA_A2_Extracted_GMM_test\\mar\\PB',\n",
        "                r'C:\\Users\\PRACHI\\OneDrive\\Desktop\\PRA_2_LID\\PRA_A2_Extracted_GMM_test\\odi\\PB',\n",
        "                r'C:\\Users\\PRACHI\\OneDrive\\Desktop\\PRA_2_LID\\PRA_A2_Extracted_GMM_test\\pun\\PB',\n",
        "                r'C:\\Users\\PRACHI\\OneDrive\\Desktop\\PRA_2_LID\\PRA_A2_Extracted_GMM_test\\tam\\PB',\n",
        "                r'C:\\Users\\PRACHI\\OneDrive\\Desktop\\PRA_2_LID\\PRA_A2_Extracted_GMM_test\\tel\\PB']\n"
      ],
      "metadata": {
        "id": "0hLf7vXVric8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Same process for all YT folder of each language.\n",
        "YT_Test_list = [r'C:\\Users\\PRACHI\\OneDrive\\Desktop\\PRA_2_LID\\PRA_A2_Extracted_GMM_test\\asm\\YT',\n",
        "                r'C:\\Users\\PRACHI\\OneDrive\\Desktop\\PRA_2_LID\\PRA_A2_Extracted_GMM_test\\ben\\YT',\n",
        "                r'C:\\Users\\PRACHI\\OneDrive\\Desktop\\PRA_2_LID\\PRA_A2_Extracted_GMM_test\\eng\\YT',\n",
        "                r'C:\\Users\\PRACHI\\OneDrive\\Desktop\\PRA_2_LID\\PRA_A2_Extracted_GMM_test\\guj\\YT',\n",
        "                r'C:\\Users\\PRACHI\\OneDrive\\Desktop\\PRA_2_LID\\PRA_A2_Extracted_GMM_test\\hin\\YT',\n",
        "                r'C:\\Users\\PRACHI\\OneDrive\\Desktop\\PRA_2_LID\\PRA_A2_Extracted_GMM_test\\kan\\YT',\n",
        "                r'C:\\Users\\PRACHI\\OneDrive\\Desktop\\PRA_2_LID\\PRA_A2_Extracted_GMM_test\\mal\\YT',\n",
        "                r'C:\\Users\\PRACHI\\OneDrive\\Desktop\\PRA_2_LID\\PRA_A2_Extracted_GMM_test\\mar\\YT',\n",
        "                r'C:\\Users\\PRACHI\\OneDrive\\Desktop\\PRA_2_LID\\PRA_A2_Extracted_GMM_test\\odi\\YT',\n",
        "                r'C:\\Users\\PRACHI\\OneDrive\\Desktop\\PRA_2_LID\\PRA_A2_Extracted_GMM_test\\pun\\YT',\n",
        "                r'C:\\Users\\PRACHI\\OneDrive\\Desktop\\PRA_2_LID\\PRA_A2_Extracted_GMM_test\\tam\\YT',\n",
        "                r'C:\\Users\\PRACHI\\OneDrive\\Desktop\\PRA_2_LID\\PRA_A2_Extracted_GMM_test\\tel\\YT']"
      ],
      "metadata": {
        "id": "fp6IE0dpr0r8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"gmm init\")\n",
        "gmm = BayesianGaussianMixture(n_components=39, random_state=42).fit(X_train)\n",
        "print(\"gmm done\")"
      ],
      "metadata": {
        "id": "mymcrEuvtzOa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# MAP adapt of mean using UBM system\n",
        "import copy\n",
        "def map_adapt(ubm,X,r=0.7):\n",
        "    gmm = copy.deepcopy(ubm)\n",
        "\n",
        "    n=np.sum(gmm.predict_proba(X),axis=0).reshape(-1,1)\n",
        "    X_tilde =(1/n) * gmm.predict_proba(X).T.dot(X)\n",
        "    alpha = (n/(n+r)).reshape(-1,1)\n",
        "    gmm.means_ = alpha * X_tilde + (1-alpha) * gmm.means_\n",
        "    return gmm"
      ],
      "metadata": {
        "id": "v_rWpWoFt1-I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gmm_models = {}\n",
        "\n",
        "print(\"Language specific GMMs after MAP estimate of means start\")\n",
        "\n",
        "gmm_models[0] = map_adapt(gmm,asm_pb_train)\n",
        "gmm_models[1] = map_adapt(gmm,ben_pb_train)\n",
        "gmm_models[2] = map_adapt(gmm,eng_pb_train)\n",
        "gmm_models[3] = map_adapt(gmm,eng_pb_train)\n",
        "gmm_models[4] = map_adapt(gmm,hin_pb_train)\n",
        "gmm_models[5] = map_adapt(gmm,kan_pb_train)\n",
        "gmm_models[6] = map_adapt(gmm,mal_pb_train)\n",
        "gmm_models[7] = map_adapt(gmm,mar_pb_train)\n",
        "gmm_models[8] = map_adapt(gmm,odi_pb_train)\n",
        "gmm_models[9] = map_adapt(gmm,pun_pb_train)\n",
        "gmm_models[10] = map_adapt(gmm,tam_pb_train)\n",
        "gmm_models[11] = map_adapt(gmm,tel_pb_train)\n",
        "\n",
        "print(\"all gmm ready\")"
      ],
      "metadata": {
        "id": "HdNtYEgnt9-g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "u=0  # Iterator to check if the predicted class match the language\n",
        "Accuracy_PB = {} # Map to note down accuracy wrt each language {0(asm): accuracy_1,1(ben) : accuracy_2 ........}\n",
        "for folders in PB_Test_list:   # Iterating through each folder\n",
        "    directory = folders        # Current folder name\n",
        "    Y=0                 # Iterator to check count of how many csv file are correctly classified to later check accuracy\n",
        "    T=0                 # Iterator to count total csv file in the folder to later check accuracy\n",
        "    for filename in os.listdir(directory):     # iterating through each test csv file in the folder\n",
        "        fs = os.path.join(directory, filename)   # path name\n",
        "        vector = pd.read_csv(fs)                 # Extracting the dataframe present in csv file\n",
        "        if vector.shape != (0,):\n",
        "\n",
        "            log_likelihood = {}                  # log_likelihood map for each language model\n",
        "            m = {}\n",
        "            for language, model in gmm_models.items():   # Language -> language number. model -> Language's GMM param.\n",
        "                gmm = model                              # We are iterating through all language model for each test file.\n",
        "                scores = np.array(gmm.score(vector))     # Score of how good it fits the language model\n",
        "                log_likelihood[language] = round(scores.sum(), 3) # Saving log likelihood for this lang. model for the given test file\n",
        "                m[language] = scores\n",
        "\n",
        "            max_log_likelihood = max(log_likelihood.values())   # Calculating the max likelihood from all models.\n",
        "            keys, values = list(log_likelihood.keys()), list(log_likelihood.values()) # Keys reperesent language number.\n",
        "            winner = keys[values.index(max_log_likelihood)]   # Extracting the lang. number of the max likelihood model\n",
        "\n",
        "        if(winner == u):                 # if it matches with the iterator\n",
        "            Y = Y +1\n",
        "        T=T+1\n",
        "    Accuracy_PB[u] = Y/T                    # Calculating Accuracy of each language class for PB data\n",
        "    u=u+1"
      ],
      "metadata": {
        "id": "YX2jdbQcuXFB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Everything is same for YT data as mentioned above.\n",
        "u=0\n",
        "Accuracy_YT = {}\n",
        "for folders in YT_Test_list:\n",
        "    directory = folders\n",
        "    Y=0\n",
        "    T=0\n",
        "    for filename in os.listdir(directory):\n",
        "        fs = os.path.join(directory, filename)\n",
        "        vector = pd.read_csv(fs)\n",
        "        if vector.shape != (0,):\n",
        "\n",
        "            log_likelihood = {}\n",
        "            m = {}\n",
        "            for language, model in gmm_models.items():\n",
        "                gmm = model\n",
        "                scores = np.array(gmm.score(vector))\n",
        "                log_likelihood[language] = round(scores.sum(), 3)\n",
        "                m[language] = scores\n",
        "\n",
        "            max_log_likelihood = max(log_likelihood.values())\n",
        "            keys, values = list(log_likelihood.keys()), list(log_likelihood.values())\n",
        "            winner = keys[values.index(max_log_likelihood)]\n",
        "\n",
        "        if(winner == u):\n",
        "            Y = Y +1\n",
        "        T=T+1\n",
        "    Accuracy_YT[u] = Y/T\n",
        "    u=u+1"
      ],
      "metadata": {
        "id": "APe1QXstueOa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Accuracy for each language in PB data')\n",
        "print(Accuracy_PB)"
      ],
      "metadata": {
        "id": "9Gsz4dh_ubTY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Accuracy for each language in YT data')\n",
        "print(Accuracy_YT)"
      ],
      "metadata": {
        "id": "1BxBBJMOuh0I"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}