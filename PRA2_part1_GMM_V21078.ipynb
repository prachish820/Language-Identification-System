{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPTxcAHKKpf4vJ4HdKCFWkD",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/prachish820/Language-Identification-System/blob/main/PRA2_part1_GMM_V21078.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### *Drive link to access data*\n",
        "\n",
        "[Extracted data](https://drive.google.com/drive/folders/11_s9A7INRwtAeUo3bdTIPXbOgMrAzs9g?usp=sharing)\n"
      ],
      "metadata": {
        "id": "j6AdcRzvq6BN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oA04_-MGpxUa"
      },
      "outputs": [],
      "source": [
        "# Importing libraries\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "from csv import reader\n",
        "from sklearn import datasets\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn import mixture\n",
        "from sklearn.mixture import BayesianGaussianMixture"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# GMM system to model each class conditional density\n",
        "\n",
        "# CLASSES  0 - asm\n",
        "#          1 - ben\n",
        "#          2 - eng\n",
        "#          3 - guj\n",
        "#          4 - Hin\n",
        "#          5 - kan\n",
        "#          6 - mal\n",
        "#          7 - mar\n",
        "#          8 - odi\n",
        "#          9 - pun\n",
        "#          10- tam\n",
        "#          11- tel"
      ],
      "metadata": {
        "id": "GQfjrW00qJ82"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training data for all language appended in one file for each. Change the directory location accordingly.\n",
        "asm_pb_train = pd.read_csv(r'C:\\Users\\PRACHI\\OneDrive\\Desktop\\PRA_2_LID\\PRA_A2_Extracted_GMM\\asm\\PB_train.csv')\n",
        "ben_pb_train = pd.read_csv(r'C:\\Users\\PRACHI\\OneDrive\\Desktop\\PRA_2_LID\\PRA_A2_Extracted_GMM\\ben\\PB_train.csv')\n",
        "eng_pb_train = pd.read_csv(r'C:\\Users\\PRACHI\\OneDrive\\Desktop\\PRA_2_LID\\PRA_A2_Extracted_GMM\\eng\\PB_train.csv')\n",
        "guj_pb_train = pd.read_csv(r'C:\\Users\\PRACHI\\OneDrive\\Desktop\\PRA_2_LID\\PRA_A2_Extracted_GMM\\guj\\PB_train.csv')\n",
        "hin_pb_train = pd.read_csv(r'C:\\Users\\PRACHI\\OneDrive\\Desktop\\PRA_2_LID\\PRA_A2_Extracted_GMM\\hin\\PB_train.csv')\n",
        "kan_pb_train = pd.read_csv(r'C:\\Users\\PRACHI\\OneDrive\\Desktop\\PRA_2_LID\\PRA_A2_Extracted_GMM\\kan\\PB_train.csv')\n",
        "mal_pb_train = pd.read_csv(r'C:\\Users\\PRACHI\\OneDrive\\Desktop\\PRA_2_LID\\PRA_A2_Extracted_GMM\\mal\\PB_train.csv')\n",
        "mar_pb_train = pd.read_csv(r'C:\\Users\\PRACHI\\OneDrive\\Desktop\\PRA_2_LID\\PRA_A2_Extracted_GMM\\mar\\PB_train.csv')\n",
        "odi_pb_train = pd.read_csv(r'C:\\Users\\PRACHI\\OneDrive\\Desktop\\PRA_2_LID\\PRA_A2_Extracted_GMM\\odi\\PB_train.csv')\n",
        "pun_pb_train = pd.read_csv(r'C:\\Users\\PRACHI\\OneDrive\\Desktop\\PRA_2_LID\\PRA_A2_Extracted_GMM\\pun\\PB_train.csv')\n",
        "tam_pb_train = pd.read_csv(r'C:\\Users\\PRACHI\\OneDrive\\Desktop\\PRA_2_LID\\PRA_A2_Extracted_GMM\\tam\\PB_train.csv')\n",
        "tel_pb_train = pd.read_csv(r'C:\\Users\\PRACHI\\OneDrive\\Desktop\\PRA_2_LID\\PRA_A2_Extracted_GMM\\tel\\PB_train.csv')\n",
        "print(\"Read training files\")"
      ],
      "metadata": {
        "id": "e2m_7rfHqqxN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# List of all the folder consisting the test csv for each audio file for PB data\n",
        "# We will be entering each folder mentioned in the list below and will read each csv file one by one to test on each\n",
        "# GMM model. Later using maximum likelihood a class from (0-11) would be assigned.\n",
        "PB_Test_list = [r'C:\\Users\\PRACHI\\OneDrive\\Desktop\\PRA_2_LID\\PRA_A2_Extracted_GMM_test\\asm\\PB',\n",
        "                r'C:\\Users\\PRACHI\\OneDrive\\Desktop\\PRA_2_LID\\PRA_A2_Extracted_GMM_test\\ben\\PB',\n",
        "                r'C:\\Users\\PRACHI\\OneDrive\\Desktop\\PRA_2_LID\\PRA_A2_Extracted_GMM_test\\eng\\PB',\n",
        "                r'C:\\Users\\PRACHI\\OneDrive\\Desktop\\PRA_2_LID\\PRA_A2_Extracted_GMM_test\\guj\\PB',\n",
        "                r'C:\\Users\\PRACHI\\OneDrive\\Desktop\\PRA_2_LID\\PRA_A2_Extracted_GMM_test\\hin\\PB',\n",
        "                r'C:\\Users\\PRACHI\\OneDrive\\Desktop\\PRA_2_LID\\PRA_A2_Extracted_GMM_test\\kan\\PB',\n",
        "                r'C:\\Users\\PRACHI\\OneDrive\\Desktop\\PRA_2_LID\\PRA_A2_Extracted_GMM_test\\mal\\PB',\n",
        "                r'C:\\Users\\PRACHI\\OneDrive\\Desktop\\PRA_2_LID\\PRA_A2_Extracted_GMM_test\\mar\\PB',\n",
        "                r'C:\\Users\\PRACHI\\OneDrive\\Desktop\\PRA_2_LID\\PRA_A2_Extracted_GMM_test\\odi\\PB',\n",
        "                r'C:\\Users\\PRACHI\\OneDrive\\Desktop\\PRA_2_LID\\PRA_A2_Extracted_GMM_test\\pun\\PB',\n",
        "                r'C:\\Users\\PRACHI\\OneDrive\\Desktop\\PRA_2_LID\\PRA_A2_Extracted_GMM_test\\tam\\PB',\n",
        "                r'C:\\Users\\PRACHI\\OneDrive\\Desktop\\PRA_2_LID\\PRA_A2_Extracted_GMM_test\\tel\\PB']\n"
      ],
      "metadata": {
        "id": "0hLf7vXVric8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Same process for all YT folder of each language.\n",
        "YT_Test_list = [r'C:\\Users\\PRACHI\\OneDrive\\Desktop\\PRA_2_LID\\PRA_A2_Extracted_GMM_test\\asm\\YT',\n",
        "                r'C:\\Users\\PRACHI\\OneDrive\\Desktop\\PRA_2_LID\\PRA_A2_Extracted_GMM_test\\ben\\YT',\n",
        "                r'C:\\Users\\PRACHI\\OneDrive\\Desktop\\PRA_2_LID\\PRA_A2_Extracted_GMM_test\\eng\\YT',\n",
        "                r'C:\\Users\\PRACHI\\OneDrive\\Desktop\\PRA_2_LID\\PRA_A2_Extracted_GMM_test\\guj\\YT',\n",
        "                r'C:\\Users\\PRACHI\\OneDrive\\Desktop\\PRA_2_LID\\PRA_A2_Extracted_GMM_test\\hin\\YT',\n",
        "                r'C:\\Users\\PRACHI\\OneDrive\\Desktop\\PRA_2_LID\\PRA_A2_Extracted_GMM_test\\kan\\YT',\n",
        "                r'C:\\Users\\PRACHI\\OneDrive\\Desktop\\PRA_2_LID\\PRA_A2_Extracted_GMM_test\\mal\\YT',\n",
        "                r'C:\\Users\\PRACHI\\OneDrive\\Desktop\\PRA_2_LID\\PRA_A2_Extracted_GMM_test\\mar\\YT',\n",
        "                r'C:\\Users\\PRACHI\\OneDrive\\Desktop\\PRA_2_LID\\PRA_A2_Extracted_GMM_test\\odi\\YT',\n",
        "                r'C:\\Users\\PRACHI\\OneDrive\\Desktop\\PRA_2_LID\\PRA_A2_Extracted_GMM_test\\pun\\YT',\n",
        "                r'C:\\Users\\PRACHI\\OneDrive\\Desktop\\PRA_2_LID\\PRA_A2_Extracted_GMM_test\\tam\\YT',\n",
        "                r'C:\\Users\\PRACHI\\OneDrive\\Desktop\\PRA_2_LID\\PRA_A2_Extracted_GMM_test\\tel\\YT']"
      ],
      "metadata": {
        "id": "fp6IE0dpr0r8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "acc_PB={key: None for key in np.arange(1,21,2)}   #Dict to save accuracy at different GMMs\n",
        "acc_YT={key: None for key in np.arange(1,21,2)}\n",
        "conf_PB={key: None for key in np.arange(1,21,2)}  #Dict to save confusion matrix at different GMMs\n",
        "conf_YT={key: None for key in np.arange(1,21,2)}"
      ],
      "metadata": {
        "id": "HSoD23vUrEQy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for key in acc_PB.keys():\n",
        "\n",
        "    # mixtures\n",
        "    #Creating GMM model for each language and saving them in a dict for later use while testing.\n",
        "    gmm_models = {}\n",
        "    confusion_PB = np.zeros((12, 12))  # Empty matrix to create confusion matrix later on to see which languages\n",
        "    confusion_YT = np.zeros((12,12))   # are getting cross-labeled\n",
        "\n",
        "    gmm_models[0] = BayesianGaussianMixture(n_components=key, random_state=42).fit(asm_pb_train)\n",
        "    gmm_models[1] = BayesianGaussianMixture(n_components=key, random_state=42).fit(ben_pb_train)\n",
        "    gmm_models[2] = BayesianGaussianMixture(n_components=key, random_state=42).fit(eng_pb_train)\n",
        "    gmm_models[3] = BayesianGaussianMixture(n_components=key, random_state=42).fit(guj_pb_train)\n",
        "    gmm_models[4] = BayesianGaussianMixture(n_components=key, random_state=42).fit(hin_pb_train)\n",
        "    gmm_models[5] = BayesianGaussianMixture(n_components=key, random_state=42).fit(kan_pb_train)\n",
        "    gmm_models[6] = BayesianGaussianMixture(n_components=key, random_state=42).fit(mal_pb_train)\n",
        "    gmm_models[7] = BayesianGaussianMixture(n_components=key, random_state=42).fit(mar_pb_train)\n",
        "    gmm_models[8] = BayesianGaussianMixture(n_components=key, random_state=42).fit(odi_pb_train)\n",
        "    gmm_models[9] = BayesianGaussianMixture(n_components=key, random_state=42).fit(pun_pb_train)\n",
        "    gmm_models[10] = BayesianGaussianMixture(n_components=key, random_state=42).fit(tam_pb_train)\n",
        "    gmm_models[11] = BayesianGaussianMixture(n_components=key, random_state=42).fit(tel_pb_train)\n",
        " \n",
        "\n",
        "    u=0  # Iterator to check if the predicted class match the language\n",
        "    Accuracy_PB = {} # Dict to note down accuracy wrt each language {0(asm): accuracy_1, 1(ben) : accuracy_2 ........}\n",
        "    for folders in PB_Test_list:   # Iterating through each folder\n",
        "        directory = folders        #Current folder name\n",
        "        Y=0                 # Iterator to check count of how many csv file are correctly classified to later check accuracy\n",
        "        T=0                 # Iterator to count total csv file in the folder to later check accuracy\n",
        "        for filename in os.listdir(directory):     # iterating through each test csv file in the folder\n",
        "            fs = os.path.join(directory, filename)   # path name\n",
        "            vector = pd.read_csv(fs)                 # Extracting the dataframe present in csv file\n",
        "            if vector.shape != (0,):\n",
        "\n",
        "                log_likelihood = {}                  # log_likelihood dict for each language model\n",
        "                m = {}\n",
        "                for language, model in gmm_models.items():   # Language -> language number. model -> Language's GMM param.\n",
        "                    gmm = model                              # We are iterating through all language model for each test file.\n",
        "                    scores = np.array(gmm.score(vector))     # Score of how good it fits the language model\n",
        "                    log_likelihood[language] = round(scores.sum(), 3) # Saving log likelihood for this lang. model for the given test file\n",
        "                    m[language] = scores\n",
        "\n",
        "                max_log_likelihood = max(log_likelihood.values())   # Calculating the max likelihood from all models.\n",
        "                keys, values = list(log_likelihood.keys()), list(log_likelihood.values()) # Keys reperesent language number.\n",
        "                winner = keys[values.index(max_log_likelihood)]   # Extracting the lang. number of the max likelihood model\n",
        "            confusion_PB[u][winner] = confusion_PB[u][winner] +1\n",
        "            if(winner == u):                 # if it matches with the iterator\n",
        "                Y = Y +1\n",
        "            T=T+1\n",
        "        Accuracy_PB[u] = Y/T                    # Calculating Accuracy of each language class for PB data\n",
        "        u=u+1\n",
        "    #print('Accuracy for each language in PB data')\n",
        "    #print(Accuracy_PB)\n",
        "    acc_PB[key]=Accuracy_PB\n",
        "    # Everything is same for YT data as mentioned above.\n",
        "    u=0\n",
        "    Accuracy_YT = {}\n",
        "    for folders in YT_Test_list:\n",
        "        directory = folders\n",
        "        Y=0\n",
        "        T=0\n",
        "        for filename in os.listdir(directory):\n",
        "            fs = os.path.join(directory, filename)\n",
        "            vector = pd.read_csv(fs)\n",
        "            if vector.shape != (0,):\n",
        "\n",
        "                log_likelihood = {}\n",
        "                m = {}\n",
        "                for language, model in gmm_models.items():\n",
        "                    gmm = model\n",
        "                    scores = np.array(gmm.score(vector))\n",
        "                    log_likelihood[language] = round(scores.sum(), 3)\n",
        "                    m[language] = scores\n",
        "\n",
        "                max_log_likelihood = max(log_likelihood.values())\n",
        "                keys, values = list(log_likelihood.keys()), list(log_likelihood.values())\n",
        "                winner = keys[values.index(max_log_likelihood)]\n",
        "            confusion_YT[u][winner] = confusion_YT[u][winner] + 1\n",
        "            if(winner == u):\n",
        "                Y = Y +1\n",
        "            T=T+1\n",
        "        Accuracy_YT[u] = Y/T\n",
        "        u=u+1\n",
        "    #print('Accuracy for each language in YT data')\n",
        "    #print(Accuracy_YT)\n",
        "    acc_YT[key]=Accuracy_YT\n",
        "\n",
        "    #print('Confusion matrix for PB data')\n",
        "    conf_PB[key]=confusion_PB\n",
        "    #print(confusion_PB)\n",
        "\n",
        "    #print('Confusion matrix for YT data')\n",
        "    conf_YT[key]=confusion_YT\n",
        "    #print(confusion_YT)"
      ],
      "metadata": {
        "id": "l6BShJRFrH1_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Accuracies for PB at different number of mixtures')\n",
        "print(acc_PB)\n",
        "print('\\n')"
      ],
      "metadata": {
        "id": "QBkroH2ssDgF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Accuracies for YT at different number of mixtures')\n",
        "print(acc_YT)\n",
        "print('\\n')"
      ],
      "metadata": {
        "id": "iFWQzsxIsmJF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Confusion matrix for PB for 13 mixtures')\n",
        "print(conf_PB[13])\n",
        "print('\\n')"
      ],
      "metadata": {
        "id": "BuKkh29CsnnQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Confusion matrix for YT for 13 mixtures')\n",
        "print(conf_YT[13])"
      ],
      "metadata": {
        "id": "7CnSKprpspAz"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}